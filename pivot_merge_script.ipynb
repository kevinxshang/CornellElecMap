{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3cac9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a30e883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "def load_and_check_dataset(file_path, building_name, year, check_date = False):\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    expected_columns = [\"name\", \"slottime_GMT\", \"pointTitle\", \"value\"]\n",
    "    expected_building_name = building_name\n",
    "    \n",
    "    # Raw dataset check\n",
    "    if df.shape[1] != 4:\n",
    "        raise ValueError(f\"Dataset must contain exactly 4 columns, but it has {df.shape[1]} columns. It might not be a raw dataset\")\n",
    "    if list(df.columns) != expected_columns:\n",
    "        raise ValueError(f\"Dataset columns are not in the expected order. Expected {expected_columns}, but got {list(df.columns)}.\")\n",
    "        \n",
    "    # Building Check\n",
    "    if not df['name'].str.startswith(expected_building_name).all():\n",
    "        raise ValueError(\"The expected building name does not match to the building names in the dataset.\")\n",
    "        \n",
    "        #warnings.warn(\"the expected building name does not match to the building names in the dataset.\")\n",
    "        #override = input(\"Do you want to override this warning and proceed? (yes/no): \")\n",
    "        #if override.lower() != 'yes':\n",
    "            #print(\"Override not confirmed. Exiting process.\")\n",
    "            #raise SystemExit\n",
    "        #else:\n",
    "            #print(\"Override confirmed. Proceeding with the process.\")\n",
    "    \n",
    "    # Missing Data Check\n",
    "    if len(df) >= 9999:\n",
    "        raise ValueError(\"DataFrame length is 9999 or more. This might be due to excessive data downloads. Try download the data following the instructions.\")\n",
    "        \n",
    "        #warnings.warn(\"DataFrame length is 9999 or more. This might due to excessive data downloads.\")\n",
    "        #override = input(\"Do you want to override this warning and proceed? (yes/no): \")\n",
    "        #if override.lower() != 'yes':\n",
    "            #print(\"Override not confirmed. Exiting process.\")\n",
    "            #raise SystemExit\n",
    "        #else:\n",
    "            #print(\"Override confirmed. Proceeding with the process.\")\n",
    "    \n",
    "    if check_date:\n",
    "        datetime_output = pd.to_datetime(df['slottime_GMT'])        \n",
    "        last_date_minus_one = datetime_output.iloc[-1] - pd.Timedelta(days=1)\n",
    "        formatted_date = last_date_minus_one.strftime('%m-%d-%Y')\n",
    "        formatted_year = last_date_minus_one.strftime('%Y')\n",
    "\n",
    "        if (datetime_output[0] != file_path[-29:-19]) or (formatted_date != file_path[-15:-5]):\n",
    "            raise ValueError(\"The date range does not match to the file's name.\")\n",
    "        \n",
    "        if (formatted_year != str(year)):\n",
    "            raise ValueError(\"The year specified does not match to the file's data.\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ecabd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "def pivot_merge_data(building_name, year):\n",
    "    \n",
    "    # MAKE SURE YOUR BUILDING NAME MATCHES TO THE PORTAL\n",
    "    folder_path = 'DataFiles_' + building_name + '_' + str(year)\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        \n",
    "        # Find all Excel Files\n",
    "        if filename.endswith('.xlsx') and (not filename.startswith(\"~$\")):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Load and check dataset\n",
    "            load_and_check_dataset(file_path, building_name, year)\n",
    "            \n",
    "            dfs.append(pd.read_excel(file_path))\n",
    "    \n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    merged_df = merged_df.drop_duplicates()\n",
    "    \n",
    "    merged_df['name'] = building_name\n",
    "    merged_df.rename(columns={'slottime_GMT': 'slottime'}, inplace=True)\n",
    "    pivot_df = merged_df.pivot_table(index = ['name', 'slottime'], columns='pointTitle', values='value').reset_index()\n",
    "    pivot_df = pivot_df.drop('Clean Room Dehumidifier Steam', axis = 1)\n",
    "    \n",
    "    pivot_df['slottime'] = pd.to_datetime(pivot_df['slottime'])\n",
    "    pivot_df = pivot_df.sort_values(by = 'slottime')\n",
    "\n",
    "    # Check dates\n",
    "    datetime_slottime = pivot_df['slottime'].dt.strftime('%m-%d-%Y')\n",
    "    datetime_slottime = pd.to_datetime(datetime_slottime, format='%m-%d-%Y')\n",
    "\n",
    "    year_to_check = year\n",
    "\n",
    "    start_date = f\"{year_to_check}-01-01\"\n",
    "    end_date = f\"{year_to_check}-12-31\"\n",
    "    full_date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "    missing_dates = full_date_range[~full_date_range.isin(datetime_slottime)]\n",
    "\n",
    "    if not missing_dates.empty:\n",
    "        warning_message = f\"Warning: There are {len(missing_dates)} dates missing for the year {year_to_check}. \"\n",
    "        warning_message += \"First five missing dates: \"\n",
    "        warning_message += ', '.join(missing_dates[:5].strftime('%m-%d-%Y'))\n",
    "        warnings.warn(warning_message)\n",
    "        override = input(\"Do you want to override this warning and proceed? (yes/no): \")\n",
    "        if override.lower() != 'yes':\n",
    "            print(\"Override not confirmed. Exiting process.\")\n",
    "            raise SystemExit\n",
    "        else:\n",
    "            print(\"Override confirmed. Proceeding with the process.\")\n",
    "    \n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10ef4169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "def save_df_to_csv(building_name, year):\n",
    "    file_path = \"CleanedDataFiles/\" + building_name + \"_\" + str(year) + '.xlsx'\n",
    "    df = pivot_merge_data(building_name, year)\n",
    "    df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d6e4bb",
   "metadata": {},
   "source": [
    "Modify the code below to pivot and merge code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d331ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/h4qjw7x550z6d6z8qtv4tyj40000gn/T/ipykernel_2765/924606708.py:48: UserWarning: Warning: There are 303 dates missing for the year 2023. First five missing dates: 02-02-2023, 02-03-2023, 02-04-2023, 02-05-2023, 02-06-2023\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to override this warning and proceed? (yes/no): yes\n",
      "Override confirmed. Proceeding with the process.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "building_name_input = \"DuffieldHall\" # Replace this name with the EXACT building name shown on the portal\n",
    "year_input = 2023 # Replace this year with the collected year\n",
    "\n",
    "save_df_to_csv(building_name_input, year_input)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
